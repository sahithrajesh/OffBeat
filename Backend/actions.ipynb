{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cc20250",
   "metadata": {
    "_sphinx_cell_id": "964da4f3-d0f1-4157-937d-4a99b911a20c"
   },
   "source": [
    "1. **Anomaly detection**\n",
    "\n",
    "   **Goal**  \n",
    "   Mark tracks whose mood is far from the playlist’s main cluster(s).\n",
    "\n",
    "   **Implementation steps**\n",
    "\n",
    "   - **Feature extraction**  \n",
    "     - Build a numeric feature vector from `audio_features` plus encoded tags (as you described to Sphinx earlier).\n",
    "\n",
    "   - **Clustering**  \n",
    "     - Cluster per playlist (e.g., KMeans/GMM with \\(K \\approx 3\\text{–}8\\)).\n",
    "\n",
    "   - **Anomaly scoring**  \n",
    "     - For each track, compute distance to nearest centroid (or \\(1 - \\max\\) cluster probability).  \n",
    "     - Define anomalies as top X% distances (e.g., 10–15%) or above a threshold.\n",
    "\n",
    "   - **Output**  \n",
    "     - For each track: anomaly score, `is_anomaly`, nearest cluster id.  \n",
    "     - Store summary like “N anomalies out of M tracks”.\n",
    "\n",
    "   - **Front‑end action**  \n",
    "     - When the user runs “anomaly detection”, call your backend endpoint that:\n",
    "       - Runs/loads the analysis for selected playlists.\n",
    "       - Returns anomaly details per track (with Spotify IDs) to display and optionally create an “anomalies” playlist.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Mood detection (clustering + visualization)**\n",
    "\n",
    "   **Goal**  \n",
    "   Show the main mood clusters in the playlist.\n",
    "\n",
    "   **Implementation**\n",
    "\n",
    "   - Reuse the same feature matrix.  \n",
    "   - After clustering:\n",
    "     - Compute centroid stats (mean energy, valence, tempo, tag frequencies) per cluster.  \n",
    "     - Auto‑label clusters with short human names (e.g., “High‑energy happy”, “Low‑energy chill”) using rules over centroids and tags.\n",
    "\n",
    "   **Visualization**\n",
    "\n",
    "   - 2D projection (PCA/UMAP) colored by cluster.  \n",
    "   - Tag clouds per cluster from Last.fm tags.\n",
    "\n",
    "   **Front‑end action**\n",
    "\n",
    "   - Display clusters as:\n",
    "     - A scatter plot (mood map).\n",
    "     - Cluster cards listing representative songs.\n",
    "\n",
    "---\n",
    "## Based on numbers 1 and 2, an analysis will be created for the rest of the actions to use info from.\n",
    "---\n",
    "\n",
    "3. **Playlist comparisons**\n",
    "\n",
    "   **Goal**  \n",
    "   Compare moods across multiple playlists.\n",
    "\n",
    "   **Implementation**\n",
    "\n",
    "   - For each playlist, compute a *mood fingerprint*:\n",
    "     - Mean of each audio feature (energy, valence, etc.).\n",
    "     - Normalized tag distribution over your mood/tag vocabulary.\n",
    "\n",
    "   - Derive summary metrics:\n",
    "     - Overall energy/valence, tempo, acousticness etc.\n",
    "     - Maybe a 2D point (valence vs energy centroid).\n",
    "\n",
    "   - **Similarity**\n",
    "     - Compute distance between mood fingerprints (e.g., cosine or Euclidean).\n",
    "     - Rank how similar playlists are to each other.\n",
    "\n",
    "   **Front‑end action**\n",
    "\n",
    "   - Show a radar chart or bar comparison of features per playlist.  \n",
    "   - Option: “These two playlists are your most similar; this one is the outlier.”\n",
    "\n",
    "---\n",
    "\n",
    "4. **Mood selection**\n",
    "\n",
    "   **Goal**  \n",
    "   Pick a target mood and show matching songs from selected playlists.\n",
    "\n",
    "   **Implementation**\n",
    "\n",
    "   - Define a fixed set of mood labels mapped to feature regions (e.g., from your clusters or a manual mapping).  \n",
    "   - For each track:\n",
    "     - Either use its cluster label (if clusters ↔ mood labels).\n",
    "     - Or compute a mood score using rules: e.g., “happy” = high valence + medium/high energy.\n",
    "\n",
    "   - Given a chosen mood:\n",
    "     - Filter tracks closest to that mood’s centroid/region.\n",
    "\n",
    "   **Front‑end action**\n",
    "\n",
    "   - Mood selector (chips/buttons).  \n",
    "   - When a mood is chosen, show a ranked list of tracks matching it, and button “Create playlist from these tracks”.\n",
    "\n",
    "---\n",
    "\n",
    "5. **Anomaly recommendations**\n",
    "\n",
    "   **Goal**  \n",
    "   Recommend songs that “fit better” than the anomalies, or that are similar to anomalies but align with playlist mood.\n",
    "\n",
    "   **Two variants**\n",
    "\n",
    "   - **“Fix my playlist”**\n",
    "     - For each anomaly, find tracks in the user’s other playlists whose features are close to the dominant playlist cluster instead of the anomaly cluster.\n",
    "     - Recommend those as replacements.\n",
    "\n",
    "   - **“Lean into the weirdness”**\n",
    "     - Find tracks similar to the anomalies (same cluster in global space) to build a “weird side‑quest” playlist.\n",
    "\n",
    "   **Implementation**\n",
    "\n",
    "   - Need a global index of the user’s `EnrichedTracks` across playlists.  \n",
    "   - Use nearest‑neighbor search in feature space to pull candidates.\n",
    "\n",
    "   **Front‑end action**\n",
    "\n",
    "   - For each anomaly, show:\n",
    "     - “Replace this with …” list.\n",
    "     - “Build an ‘anomaly vibes’ playlist” button.\n",
    "\n",
    "---\n",
    "\n",
    "6. **Mood recommendations**\n",
    "\n",
    "   **Goal**  \n",
    "   Given a mood, recommend tracks from *outside* the selected playlist(s) but within the user’s library or beyond.\n",
    "\n",
    "   **Implementation (within user’s library)**\n",
    "\n",
    "   - Build a mood centroid from:\n",
    "     - Selected mood label → target centroid (from your clusters/global stats).\n",
    "   - Across all user’s `EnrichedTracks`:\n",
    "     - Find nearest tracks to that centroid not already in the active playlist(s).\n",
    "\n",
    "   - If you want to go beyond the user’s songs, you could later integrate ReccoBeats or Spotify recommendations as a second step, but that’s optional for the datathon.\n",
    "\n",
    "   **Front‑end action**\n",
    "\n",
    "   - “More songs for this mood” button on mood selection results.\n",
    "\n",
    "---\n",
    "\n",
    "7. **Sphinx chatbot integration**\n",
    "\n",
    "   **Goal**  \n",
    "   Let users ask questions like “Why is this song an anomaly?” or “Which playlist is happiest?”.\n",
    "\n",
    "   **Architecture**\n",
    "\n",
    "   - **Data surface for Sphinx**:\n",
    "     - In a notebook (local or Databricks), load:\n",
    "       - The `EnrichedTracks`.\n",
    "       - All derived analysis tables (clusters, anomalies, fingerprints).\n",
    "\n",
    "   - **Sphinx CLI / agent**:\n",
    "     - Run Sphinx in “agent” or “plan” mode over that notebook kernel.\n",
    "     - Give it a description of the dataframes/dicts and the actions (like the scenario you already wrote).\n",
    "\n",
    "   - **App integration**:\n",
    "     - Your app sends user questions → a backend route that:\n",
    "       - Forwards the question to Sphinx CLI (e.g., via subprocess or HTTP if you proxy it).\n",
    "       - Sphinx reads the dataframes, generates/executes code, and returns a natural language answer plus optional tables/plots.\n",
    "     - You can predefine some “shortcuts” in Sphinx rules, e.g.,\n",
    "       - “anomalies for playlist X” → call `get_anomalies(playlist_id)`\n",
    "       - “compare playlist A and B” → call `compare_playlists([A, B])`\n",
    "\n",
    "---\n",
    "\n",
    "8. **Creating playlists from results**\n",
    "\n",
    "   **Goal**  \n",
    "   Turn any list of Spotify track IDs into a new playlist via the Web API.\n",
    "\n",
    "   **Implementation**\n",
    "\n",
    "   - **Backend helper**:\n",
    "     - `create_playlist(user_id, name, description, is_public)` → call Spotify “Create Playlist” API.\n",
    "     - `add_tracks_to_playlist(playlist_id, track_spotify_ids)`.\n",
    "\n",
    "   - **Wire into actions**:\n",
    "     - Anomaly detection:\n",
    "       - “Create playlist of anomalies.”\n",
    "     - Mood selection:\n",
    "       - “Create playlist of ‘High‑energy happy’ songs from selected playlists.”\n",
    "     - Anomaly/mood recommendations:\n",
    "       - “Create recommended playlist” from candidate tracks.\n",
    "\n",
    "   - Optional: store a link between analysis runs and created playlist IDs for traceability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9a794",
   "metadata": {
    "_sphinx_cell_id": "6f244190-0707-4689-b758-bf8d293e3bd6"
   },
   "outputs": [],
   "source": [
    "\"\"\"Data classes shared across modules.\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Artist:\n",
    "    name: str\n",
    "    spotify_id: Optional[str] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Track:\n",
    "    \"\"\"Minimal Spotify track info collected from playlists.\"\"\"\n",
    "\n",
    "    spotify_id: str\n",
    "    title: str\n",
    "    artists: list[Artist]\n",
    "    album_name: str\n",
    "    duration_ms: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AudioFeatures:\n",
    "    \"\"\"Audio features retrieved from ReccoBeats.\"\"\"\n",
    "\n",
    "    acousticness: float\n",
    "    danceability: float\n",
    "    energy: float\n",
    "    instrumentalness: float\n",
    "    liveness: float\n",
    "    loudness: float\n",
    "    speechiness: float\n",
    "    tempo: float\n",
    "    valence: float\n",
    "    key: Optional[int] = None\n",
    "    mode: Optional[int] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Tag:\n",
    "    \"\"\"A single Last.fm tag with its weight.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    count: int  # 0-100 relevance weight\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EnrichedTrack:\n",
    "    \"\"\"Final fused object combining Spotify metadata, ReccoBeats features, and\n",
    "    Last.fm tags.  This is the object handed off to later data-processing code.\n",
    "    \"\"\"\n",
    "\n",
    "    spotify_id: str\n",
    "    title: str\n",
    "    artists: list[Artist]\n",
    "    album_name: str\n",
    "    duration_ms: int\n",
    "    audio_features: Optional[AudioFeatures] = None\n",
    "    tags: list[Tag] = field(default_factory=list)\n",
    "\n",
    "    # ReccoBeats internal id (useful for further API calls)\n",
    "    reccobeats_id: Optional[str] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Playlist:\n",
    "    \"\"\"Basic Spotify playlist metadata (without tracks).\"\"\"\n",
    "\n",
    "    spotify_id: str\n",
    "    name: str\n",
    "    total_tracks: int\n",
    "    owner: str\n",
    "    description: Optional[str] = None\n",
    "    image_url: Optional[str] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EnrichedPlaylist:\n",
    "    \"\"\"A playlist represented as a collection of EnrichedTracks.\"\"\"\n",
    "\n",
    "    spotify_id: str\n",
    "    name: str\n",
    "    tracks: list[EnrichedTrack] = field(default_factory=list)\n",
    "    description: Optional[str] = None\n",
    "    owner: Optional[str] = None\n",
    "    snapshot_id: Optional[str] = None\n",
    "    image_url: Optional[str] = None\n",
    "    total_tracks: int = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065cc7cd",
   "metadata": {
    "_sphinx_cell_id": "d90fd665-2970-40ba-8202-6a69b4f9bbe1"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import models\n",
    "\n",
    "# We expect models to define:\n",
    "# models.Artist\n",
    "# models.AudioFeatures\n",
    "# models.Tag\n",
    "# models.EnrichedTrack\n",
    "# models.EnrichedPlaylist\n",
    "\n",
    "DATA_PATH = Path(\"enriched_playlists.json\")\n",
    "\n",
    "with DATA_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    raw_playlists = json.load(f)\n",
    "\n",
    "def artist_from_dict(d: dict) -> models.Artist:\n",
    "    return models.Artist(\n",
    "        name=d[\"name\"],\n",
    "        spotify_id=d.get(\"spotify_id\"),\n",
    "    )\n",
    "\n",
    "def audio_features_from_dict(d: dict | None) -> models.AudioFeatures | None:\n",
    "    if d is None:\n",
    "        return None\n",
    "    return models.AudioFeatures(\n",
    "        acousticness=d[\"acousticness\"],\n",
    "        danceability=d[\"danceability\"],\n",
    "        energy=d[\"energy\"],\n",
    "        instrumentalness=d[\"instrumentalness\"],\n",
    "        liveness=d[\"liveness\"],\n",
    "        loudness=d[\"loudness\"],\n",
    "        speechiness=d[\"speechiness\"],\n",
    "        tempo=d[\"tempo\"],\n",
    "        valence=d[\"valence\"],\n",
    "        key=d.get(\"key\"),\n",
    "        mode=d.get(\"mode\"),\n",
    "    )\n",
    "\n",
    "def tag_from_dict(d: dict) -> models.Tag:\n",
    "    return models.Tag(\n",
    "        name=d[\"name\"],\n",
    "        count=d[\"count\"],\n",
    "    )\n",
    "\n",
    "def enriched_track_from_dict(d: dict) -> models.EnrichedTrack:\n",
    "    return models.EnrichedTrack(\n",
    "        spotify_id=d[\"spotify_id\"],\n",
    "        title=d[\"title\"],\n",
    "        artists=[artist_from_dict(a) for a in d.get(\"artists\", [])],\n",
    "        album_name=d[\"album_name\"],\n",
    "        duration_ms=d[\"duration_ms\"],\n",
    "        audio_features=audio_features_from_dict(d.get(\"audio_features\")),\n",
    "        tags=[tag_from_dict(t) for t in d.get(\"tags\", [])],\n",
    "        reccobeats_id=d.get(\"reccobeats_id\"),\n",
    "    )\n",
    "\n",
    "def enriched_playlist_from_dict(d: dict) -> models.EnrichedPlaylist:\n",
    "    return models.EnrichedPlaylist(\n",
    "        spotify_id=d[\"spotify_id\"],\n",
    "        name=d[\"name\"],\n",
    "        tracks=[enriched_track_from_dict(t) for t in d.get(\"tracks\", [])],\n",
    "    )\n",
    "\n",
    "example_playlists: list[models.EnrichedPlaylist] = [\n",
    "    enriched_playlist_from_dict(p) for p in raw_playlists\n",
    "]\n",
    "\n",
    "# Quick sanity check\n",
    "print(f\"Loaded {len(example_playlists)} playlist(s)\")\n",
    "for pl in example_playlists:\n",
    "    print(f\"- {pl.name}: {len(pl.tracks)} tracks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51017349",
   "metadata": {
    "_sphinx_cell_id": "87aab352-01ee-4c54-89f8-fcce4e208a63"
   },
   "source": [
    "We will implement the following analysis functions:\n",
    "\n",
    "- run_anomaly_detection(playlist: EnrichedPlaylist) -> dict\n",
    "\n",
    "- run_mood_clustering(playlist: EnrichedPlaylist) -> dict\n",
    "\n",
    "- compare_playlists(playlists: list[EnrichedPlaylist]) -> dict\n",
    "\n",
    "- select_tracks_by_mood(playlists: list[EnrichedPlaylist], mood_label: str) -> dict\n",
    "\n",
    "- recommend_for_anomalies(playlists: list[EnrichedPlaylist]) -> dict\n",
    "\n",
    "- recommend_for_mood(playlists: list[EnrichedPlaylist], mood_label: str) -> dict\n",
    "\n",
    "All functions must:\n",
    "\n",
    "- Take EnrichedPlaylist / list[EnrichedPlaylist] and optional mood_label as input.\n",
    "\n",
    "- Use EnrichedPlaylist.tracks (list of EnrichedTrack) as the data source.\n",
    "\n",
    "- Handle missing audio_features and/or empty tags without crashing.\n",
    "\n",
    "- Return JSON‑serializable dicts ready to send from a backend API to a front‑end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c83045",
   "metadata": {
    "_sphinx_cell_id": "6fa411d2-d7fd-46f7-a436-73d2062085b8"
   },
   "source": [
    "You are a data‑science coding agent working in this notebook.\n",
    "\n",
    "The core data model is:\n",
    "\n",
    "- `EnrichedPlaylist` with fields:\n",
    "  - `spotify_id: str`\n",
    "  - `name: str`\n",
    "  - `tracks: list[EnrichedTrack]`\n",
    "- `EnrichedTrack` has:\n",
    "  - `spotify_id`, `title`, `artists`, `album_name`, `duration_ms`\n",
    "  - `audio_features: Optional[AudioFeatures]`\n",
    "  - `tags: list[Tag]`\n",
    "  - `reccobeats_id: Optional[str]`\n",
    "- `AudioFeatures` contains numeric audio features:\n",
    "  - `acousticness`, `danceability`, `energy`, `instrumentalness`, `liveness`, `loudness`, `speechiness`, `tempo`, `valence`, `key`, `mode`\n",
    "- `Tag` contains:\n",
    "  - `name: str` (text)\n",
    "  - `count: int` (0–100 relevance)\n",
    "\n",
    "We already use `EnrichedTrack` as the fused object containing Spotify metadata, ReccoBeats audio features, and Last.fm tags.\n",
    "\n",
    "---\n",
    "\n",
    "## Functions to implement\n",
    "\n",
    "Implement the following Python functions in this notebook.\n",
    "\n",
    "Each function must:\n",
    "\n",
    "- Take `EnrichedPlaylist` or `list[EnrichedPlaylist]` objects as input.\n",
    "- Construct feature matrices from `audio_features` + encoded `tags`.\n",
    "- Handle missing data robustly:\n",
    "  - If a track has neither `audio_features` nor `tags`, exclude it from numerical clustering, but report it separately.\n",
    "  - If a track has only `audio_features`, use numeric features only.\n",
    "  - If a track has only `tags`, use tag‑based features only for that part.\n",
    "- Return JSON‑serializable Python dicts (no custom classes in the return value).\n",
    "- Never crash due to missing fields.\n",
    "\n",
    "### 1. `run_playlist_analysis(playlist: EnrichedPlaylist) -> dict`\n",
    "\n",
    "This is the **combined analysis** action (mood clustering + anomaly detection).  \n",
    "Other actions will reuse its outputs.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "- Build a mood feature space for the playlist using `EnrichedTrack` features.\n",
    "- Cluster tracks into 3–8 mood clusters using combined features.\n",
    "- For each cluster:\n",
    "  - Compute centroid feature summary (mean energy, valence, tempo, tag distribution).\n",
    "  - Assign a simple label like `\"high_energy_happy\"` based on rules.\n",
    "- Compute an anomaly score per track (e.g., distance to nearest cluster center or low cluster membership probability).\n",
    "- Mark the top X% as anomalies.\n",
    "- Return a dict with:\n",
    "  - `\"playlist_id\"`, `\"playlist_name\"`\n",
    "  - `\"clusters\"`: list of clusters with  \n",
    "    `cluster_id`, `label`, `size`, `centroid_features`, and list of member `spotify_id`s.\n",
    "  - `\"tracks\"`: list of objects with  \n",
    "    `spotify_id`, `title`, `cluster_id`, `anomaly_score`, `is_anomaly`, and a brief text `\"reason\"` field explaining why it’s an anomaly (if `is_anomaly` is true).\n",
    "  - `\"summary\"`: overall stats for the playlist (e.g., `num_tracks`, `num_anomalies`, `num_clusters`, any tracks excluded due to missing data).\n",
    "\n",
    "Later functions should assume they can consume the outputs of `run_playlist_analysis` instead of recomputing clustering/anomalies from scratch.\n",
    "\n",
    "### 2. `compare_playlists(playlists: list[EnrichedPlaylist]) -> dict`\n",
    "\n",
    "- For each playlist, compute a mood fingerprint using the analysis results from `run_playlist_analysis` when available:\n",
    "  - Mean audio features (energy, valence, etc.).\n",
    "  - Normalized tag distribution over a small mood/tag vocabulary you infer from the data.\n",
    "  - Optional: aggregate cluster information (e.g., distribution over mood labels).\n",
    "- Compute pairwise similarity/distance between playlists.\n",
    "- Return:\n",
    "  - `\"playlists\"`: list with `playlist_id`, `name`, `fingerprint` (features).\n",
    "  - `\"similarities\"`: list of `{ \"playlist_id_a\", \"playlist_id_b\", \"distance\" }`.\n",
    "\n",
    "### 3. `select_tracks_by_mood(playlists: list[EnrichedPlaylist], mood_label: str) -> dict`\n",
    "\n",
    "- Use the existing mood feature space or the cluster labels from `run_playlist_analysis` to find tracks that match `mood_label` from the selected playlists.\n",
    "- If a playlist has not yet been analyzed, call `run_playlist_analysis` internally or document that it must be precomputed.\n",
    "- Return:\n",
    "  - `\"mood_label\"`\n",
    "  - `\"tracks\"`: list with  \n",
    "    `spotify_id`, `title`, `playlist_id`, `playlist_name`, `cluster_id` (if applicable), and a `\"match_score\"`.\n",
    "\n",
    "### 4. `recommend_for_anomalies(playlists: list[EnrichedPlaylist]) -> dict`\n",
    "\n",
    "- Use the anomaly detection results from `run_playlist_analysis`.\n",
    "- For each anomaly track in each playlist:\n",
    "  - Identify the dominant mood cluster(s) of that playlist.\n",
    "  - Suggest a few replacement tracks from the user’s *other* playlists that better fit the dominant mood cluster (using the same feature space).\n",
    "- Return:\n",
    "  - `\"recommendations\"`: list of items with  \n",
    "    `playlist_id`, `playlist_name`,  \n",
    "    `anomaly_track_id`, `anomaly_title`,  \n",
    "    and a list of suggested replacement tracks (`spotify_id`, `title`, `source_playlist_id`, `source_playlist_name`, `fit_score`).\n",
    "\n",
    "### 5. `recommend_for_mood(playlists: list[EnrichedPlaylist], mood_label: str) -> dict`\n",
    "\n",
    "- Given a mood label, use the mood feature space / clusters from `run_playlist_analysis` to find tracks across the provided playlists that match the mood but are *not* already in a specific target playlist (or simply return all matching tracks with scores).\n",
    "- Return:\n",
    "  - `\"mood_label\"`\n",
    "  - `\"tracks\"`: list with  \n",
    "    `spotify_id`, `title`, `playlist_id`, `playlist_name`, `cluster_id` (if applicable), and `\"match_score\"`.\n",
    "\n",
    "---\n",
    "\n",
    "## General requirements\n",
    "\n",
    "- Use idiomatic Python with `numpy` / `pandas` / `scikit-learn` for feature construction and clustering.\n",
    "- Encapsulate common logic (feature extraction, tag encoding, clustering, distance / similarity computations) into helper functions to avoid duplication.\n",
    "- Prefer reusing the outputs of `run_playlist_analysis` instead of re‑clustering whenever possible.\n",
    "- Provide at least one example call per function using `example_playlists` (or a small synthetic playlist) to demonstrate usage.\n",
    "- Make sure all code runs in this notebook without external dependencies beyond standard data‑science libraries.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
